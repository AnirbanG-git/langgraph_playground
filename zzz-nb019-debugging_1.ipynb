{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be46161e-45e9-46d7-8214-bcbea10aff2e",
   "metadata": {},
   "source": [
    "# Debugging\n",
    "* LangGraph supports debugging by viewing, re-playing, and even forking from past states.\n",
    "* **The LangGraph team sometimes calls these techniques \"time travel\"**, since what they do is to allow you to run the app starting from a chosen step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9983fc1c-3724-4b01-b35a-9afded632157",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871e0018-cba4-4959-881a-0a65093d202d",
   "metadata": {},
   "source": [
    "#### After you download the code from the github repository in your computer\n",
    "In terminal:\n",
    "* cd project_name\n",
    "* pyenv local 3.11.4\n",
    "* poetry install\n",
    "* poetry shell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4065e336-d054-412c-8a3f-1fbec63e1bcd",
   "metadata": {},
   "source": [
    "#### To open the notebook with Jupyter Notebooks\n",
    "In terminal:\n",
    "* jupyter lab\n",
    "\n",
    "Go to the folder of notebooks and open the right notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dda8d4-80cf-4b8f-9981-94edda5e9911",
   "metadata": {},
   "source": [
    "#### To see the code in Virtual Studio Code or your editor of choice.\n",
    "* open Virtual Studio Code or your editor of choice.\n",
    "* open the project-folder\n",
    "* open the 019-debugging.py file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af743328-1bc8-4b01-85fb-fcb21c6499c2",
   "metadata": {},
   "source": [
    "## Create your .env file\n",
    "* In the github repo we have included a file named .env.example\n",
    "* Rename that file to .env file and here is where you will add your confidential api keys. Remember to include:\n",
    "* OPENAI_API_KEY=your_openai_api_key\n",
    "* LANGCHAIN_TRACING_V2=true\n",
    "* LANGCHAIN_ENDPOINT=https://api.smith.langchain.com\n",
    "* LANGCHAIN_API_KEY=your_langchain_api_key\n",
    "* LANGCHAIN_PROJECT=your_project_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e766aa-f3e2-491f-be99-d0c6b700d47a",
   "metadata": {},
   "source": [
    "## Track operations\n",
    "From now on, we can track the operations **and the cost** of this project from LangSmith:\n",
    "* [smith.langchain.com](https://smith.langchain.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f99504a-1b8f-4360-b342-0b81ffa06aff",
   "metadata": {},
   "source": [
    "## Connect with the .env file located in the same directory of this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39e5789-5bde-42e1-88dd-92dc8e363c24",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5514113-ddca-4ae9-9de6-0b9225b18f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fecd39d0-e72e-4bc2-8a68-2fa4008ea365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "os.environ[\"http_proxy\"] = \"\"\n",
    "os.environ[\"https_proxy\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f4a923-b19e-498e-9be5-e47ec4a77d80",
   "metadata": {},
   "source": [
    "#### Install LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fef1e5c-b7e2-4a04-96c5-8f64377b8eba",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1cf94ae-6c39-4475-9c5b-4b74d8d78753",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189e9e17-dfb0-4fd3-85b9-1fba83771941",
   "metadata": {},
   "source": [
    "## Connect with an LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21d23f4-61f5-4227-8a75-7eefde6680ee",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "148df8e0-361d-4ddd-8709-af48fa1648d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df978ec5-bfd2-4167-bd33-86bc2687d1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chatModel35 = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "chatModel4o = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0030a33d-2721-4bc3-a221-e83d1ac93a85",
   "metadata": {},
   "source": [
    "## Initial app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac315424-16ae-4f0b-8140-96bc6ef25b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "# This will be a tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "def divide(a: int, b: int) -> float:\n",
    "    \"\"\"Adds a and b.\n",
    "\n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a / b\n",
    "\n",
    "tools = [add, multiply, divide]\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1392bb61-f258-41a7-b592-9f213aecf68e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from langgraph.prebuilt import tools_condition, ToolNode\n",
    "\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "# System message\n",
    "sys_msg = SystemMessage(content=\"You are a helpful assistant tasked with performing arithmetic on a set of inputs.\")\n",
    "\n",
    "# Node\n",
    "def assistant(state: MessagesState):\n",
    "   return {\"messages\": [llm_with_tools.invoke([sys_msg] + state[\"messages\"])]}\n",
    "\n",
    "# Graph\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# Define nodes: these do the work\n",
    "builder.add_node(\"assistant\", assistant)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "# Define edges: these determine the control flow\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "graph = builder.compile(checkpointer=MemorySaver())\n",
    "\n",
    "# Show\n",
    "display(Image(graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2e797a1-de58-4b67-90f5-5ef1dce1653d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply 2 and 3\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_KAbBbJbelVgFS20v4KgztnqC)\n",
      " Call ID: call_KAbBbJbelVgFS20v4KgztnqC\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 3\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "6\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of multiplying 2 and 3 is 6.\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "initial_input = {\"messages\": HumanMessage(content=\"Multiply 2 and 3\")}\n",
    "\n",
    "# Thread\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Run the graph until the first interruption\n",
    "for event in graph.stream(initial_input, thread, stream_mode=\"values\"):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570e9073-1dbd-4f04-bc10-7245622a9849",
   "metadata": {},
   "source": [
    "## Using get_state to look at the current state and thread of the app\n",
    "* **graph.get_state()** provides the most recent step.\n",
    "* We can use get_state to look at the current state of our app, given the thread_id:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49909b4d-cb03-4bda-a41d-820f4d727bb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='Multiply 2 and 3', additional_kwargs={}, response_metadata={}, id='bcd6c2b4-c3df-498f-9149-a9cdda9f645c'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_KAbBbJbelVgFS20v4KgztnqC', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 131, 'total_tokens': 149, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_90d33c15d4', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-82104a6b-e1b1-451c-b24d-4ceb6fd41e6f-0', tool_calls=[{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_KAbBbJbelVgFS20v4KgztnqC', 'type': 'tool_call'}], usage_metadata={'input_tokens': 131, 'output_tokens': 18, 'total_tokens': 149, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='6', name='multiply', id='c0af1d76-777e-439d-a5f2-5e00646e7f49', tool_call_id='call_KAbBbJbelVgFS20v4KgztnqC'), AIMessage(content='The result of multiplying 2 and 3 is 6.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 156, 'total_tokens': 171, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_90d33c15d4', 'finish_reason': 'stop', 'logprobs': None}, id='run-fc0ddf8b-8fd3-4a32-8951-bd5d291a4050-0', usage_metadata={'input_tokens': 156, 'output_tokens': 15, 'total_tokens': 171, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f008d0f-d71e-6e36-8003-f15f2ae6187f'}}, metadata={'source': 'loop', 'writes': {'assistant': {'messages': [AIMessage(content='The result of multiplying 2 and 3 is 6.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 156, 'total_tokens': 171, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_90d33c15d4', 'finish_reason': 'stop', 'logprobs': None}, id='run-fc0ddf8b-8fd3-4a32-8951-bd5d291a4050-0', usage_metadata={'input_tokens': 156, 'output_tokens': 15, 'total_tokens': 171, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}, 'thread_id': '1', 'step': 3, 'parents': {}}, created_at='2025-03-24T16:56:54.680728+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f008d0f-cf5a-610a-8002-9b7a0db923c0'}}, tasks=())"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_state({'configurable': {'thread_id': '1'}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfbc88e-071d-46ee-bc3c-83a84e49f1fa",
   "metadata": {},
   "source": [
    "## Here’s a more readable version of the previous response\n",
    "\n",
    "#### State  \n",
    "**Messages**:  \n",
    "1. **User Message**  \n",
    "   - **Content**: \"Multiply 2 and 3\"  \n",
    "   - **ID**: `4ee8c440-0e4a-47d7-852f-06e2a6c4f84d`  \n",
    "\n",
    "2. **AI Message** (Initial response)  \n",
    "   - **Content**: *(Empty)*  \n",
    "   - **Tool Call**:  \n",
    "     - **ID**: `call_ikJxMpb777bKMYgmM3d9mYjW`  \n",
    "     - **Function**:  \n",
    "       - **Name**: `multiply`  \n",
    "       - **Arguments**: `{\"a\": 2, \"b\": 3}`  \n",
    "     - **Type**: `function`  \n",
    "   - **Metadata**:  \n",
    "     - **Tokens Used**:  \n",
    "       - Completion: 17  \n",
    "       - Prompt: 131  \n",
    "       - Total: 148  \n",
    "     - **Model**: `gpt-4o-2024-05-13`  \n",
    "     - **Finish Reason**: `tool_calls`  \n",
    "   - **ID**: `run-bc24d334-8013-4f85-826f-e1ed69c86df0-0`  \n",
    "\n",
    "3. **Tool Message** (Tool Response)  \n",
    "   - **Content**: `6`  \n",
    "   - **Tool Name**: `multiply`  \n",
    "   - **ID**: `1012611a-30c5-4732-b789-8c455580c7b4`  \n",
    "   - **Tool Call ID**: `call_ikJxMpb777bKMYgmM3d9mYjW`  \n",
    "\n",
    "4. **AI Message** (Final Output)  \n",
    "   - **Content**: \"The result of multiplying 2 and 3 is 6.\"  \n",
    "   - **Metadata**:  \n",
    "     - **Tokens Used**:  \n",
    "       - Completion: 14  \n",
    "       - Prompt: 156  \n",
    "       - Total: 170  \n",
    "     - **Model**: `gpt-4o-2024-05-13`  \n",
    "     - **Finish Reason**: `stop`  \n",
    "   - **ID**: `run-b46f3fed-ca3b-4e09-83f4-77ea5071e9bf-0`  \n",
    "\n",
    "#### Next Steps  \n",
    "- **Next**: *(Empty)*  \n",
    "\n",
    "\n",
    "#### Configuration  \n",
    "- **Thread ID**: `1`  \n",
    "- **Checkpoint ID**: `1ef6a440-ac9e-6024-8003-6fd8435c1d3b`  \n",
    "\n",
    "\n",
    "#### Metadata  \n",
    "- **Source**: `loop`  \n",
    "- **Writes**:  \n",
    "  - Assistant Message: \"The result of multiplying 2 and 3 is 6.\"  \n",
    "- **Step**: `3`  \n",
    "\n",
    "\n",
    "#### Creation Details  \n",
    "- **Timestamp**: `2024-09-03T22:29:54.309727+00:00`  \n",
    "\n",
    "\n",
    "#### Parent Configuration  \n",
    "- **Checkpoint ID**: `1ef6a440-a759-6d02-8002-f1da6393e1ab`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67690b56-d72f-4b5a-ae0e-3ef3034b7284",
   "metadata": {},
   "source": [
    "## We can now use **get_state_history** to get the state at all prior steps:\n",
    "* **graph.get_state_history()** provides list of all steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "306990eb-f734-4283-b668-a0c072acadc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_states = [s for s in graph.get_state_history(thread)]\n",
    "\n",
    "len(all_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c292abad-48d5-4f35-b26d-91e1036a0d69",
   "metadata": {},
   "source": [
    "## Let's display the state in one particular step of the app workflow\n",
    "* We will do this to debug it, when the app is not working well in that particular step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7480315-3d8b-450b-9f61-bcff66e61320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='Multiply 2 and 3', additional_kwargs={}, response_metadata={}, id='bcd6c2b4-c3df-498f-9149-a9cdda9f645c')]}, next=('assistant',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f008d0f-9378-6ad8-8000-19bf2a734b44'}}, metadata={'source': 'loop', 'writes': None, 'thread_id': '1', 'step': 0, 'parents': {}}, created_at='2025-03-24T16:56:47.587190+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f008d0f-9374-63a2-bfff-a579f25481d4'}}, tasks=(PregelTask(id='c5cf33f3-710d-7e5b-b135-ed20f399c618', name='assistant', path=('__pregel_pull', 'assistant'), error=None, interrupts=(), state=None, result={'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_KAbBbJbelVgFS20v4KgztnqC', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 131, 'total_tokens': 149, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_90d33c15d4', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-82104a6b-e1b1-451c-b24d-4ceb6fd41e6f-0', tool_calls=[{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'call_KAbBbJbelVgFS20v4KgztnqC', 'type': 'tool_call'}], usage_metadata={'input_tokens': 131, 'output_tokens': 18, 'total_tokens': 149, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}),))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_states[-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1e6258-9a03-4af8-aa37-cdf669c8e22d",
   "metadata": {},
   "source": [
    "## Here is a more readable format of the previous response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edc2196-8242-499e-95a7-ec923499fa78",
   "metadata": {},
   "source": [
    "#### State  \n",
    "\n",
    "**Messages**:  \n",
    "1. **User Message**  \n",
    "   - **Content**: \"Multiply 2 and 3\"  \n",
    "   - **ID**: `6962373e-91bd-41cb-8cdf-f8a646b024ef`  \n",
    "   - **Additional Data**: *(None)*  \n",
    "\n",
    "#### Next Steps:  \n",
    "- **Next**: `assistant`  \n",
    "\n",
    "#### Configuration:  \n",
    "- **Thread ID**: `1`  \n",
    "- **Checkpoint ID**: `1efbb93b-56d0-6f56-8000-babbdc48f6e3`  \n",
    "\n",
    "#### Metadata:  \n",
    "- **Source**: `loop`  \n",
    "- **Writes**: *(None)*  \n",
    "- **Thread ID**: `1`  \n",
    "- **Step**: `0`  \n",
    "\n",
    "#### Creation Details:  \n",
    "- **Timestamp**: `2024-12-16T09:54:15.018467+00:00`  \n",
    "\n",
    "#### Parent Configuration:  \n",
    "- **Checkpoint ID**: `1efbb93b-56c8-6194-bfff-94fdcd886b5f`  \n",
    "\n",
    "#### Tasks:  \n",
    "\n",
    "**Task Information**  \n",
    "- **Task ID**: `bea2ad80-4a1b-dca8-9a54-345a75929c17`  \n",
    "- **Name**: `assistant`  \n",
    "- **Path**: `('__pregel_pull', 'assistant')`  \n",
    "- **State**: *(None)*  \n",
    "\n",
    "#### Task Result:  \n",
    "\n",
    "**AI Message** (Initial Response)  \n",
    "- **Content**: *(Empty)*  \n",
    "- **Tool Calls**:  \n",
    "  1. **Tool Call ID**: `call_MSecnS0bCms5CM8Q7YqpUmhV`  \n",
    "     - **Function**:  \n",
    "       - **Name**: `multiply`  \n",
    "       - **Arguments**: `{\"a\": 2, \"b\": 3}`  \n",
    "     - **Type**: `function`  \n",
    "\n",
    "#### Metadata for AI Message:  \n",
    "- **Tokens Used**:  \n",
    "  - Completion: 17  \n",
    "  - Prompt: 131  \n",
    "  - Total: 148  \n",
    "- **Model**: `gpt-4o-2024-08-06`  \n",
    "- **Finish Reason**: `tool_calls`  \n",
    "\n",
    "#### Usage Metadata:  \n",
    "- **Input Tokens**: 131  \n",
    "- **Output Tokens**: 17  \n",
    "- **Total Tokens**: 148  \n",
    "\n",
    "**Token Details**:  \n",
    "- **Input**:  \n",
    "  - Audio: 0  \n",
    "  - Cache Read: 0  \n",
    "- **Output**:  \n",
    "  - Audio: 0  \n",
    "  - Reasoning: 0  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc2d725-cdf6-414c-8d3c-ce7b6fad0bde",
   "metadata": {},
   "source": [
    "## Here’s what the previous code does, broken down step by step:\n",
    "\n",
    "1. **`graph.get_state_history(thread)`**:\n",
    "   - This function is part of the LangGraph library. \n",
    "   - It retrieves the history of states for a particular `thread`.\n",
    "\n",
    "2. **`[s for s in graph.get_state_history(thread)]`**:\n",
    "   - This is a **list comprehension**. It iterates over each state in the state history returned by `graph.get_state_history(thread)` and creates a list of all those states.\n",
    "   - The resulting list, `all_states`, contains all the states the thread has been in, in chronological order.\n",
    "\n",
    "3. **`len(all_states)`**:\n",
    "   - This calculates the total number of states in `all_states`, i.e., the number of states the thread has transitioned through.\n",
    "\n",
    "4. **`all_states[-2]`**:\n",
    "   - This accesses the second-to-last state in the list. In Python, negative indexing allows you to count from the end of a list, where `-1` is the last item, `-2` is the second-to-last, and so on.\n",
    "   - `all_states[-2]` retrieves the penultimate state in the thread’s history."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23c2214-d2b2-4075-bb57-7607fce39530",
   "metadata": {},
   "source": [
    "## How to re-play one particular step so we can debug it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb448dcc-ca6d-4f55-95af-c8cec75a9ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f008d0f-9378-6ad8-8000-19bf2a734b44'}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_to_replay = all_states[-2]\n",
    "\n",
    "step_to_replay.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "511b588d-bed2-4ef8-867f-01a6b132ea9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('assistant',)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_to_replay.next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fd0d48-5449-4f90-9508-3ad148a17afe",
   "metadata": {},
   "source": [
    "#### To replay from here, we simply pass the config back to the agent.\n",
    "* The graph knows that this step (aka checkpoint) has aleady been executed.\n",
    "* It just re-plays from this step (aka checkpoint).\n",
    "* In other words, **graph.stream(None, {particular_step, thread_id})** executes graph from the particular_step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40f229b9-54da-41c8-b7cf-8386abec9f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply 2 and 3\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_FeH4RMy4J5xUm9u5HAuMGeXf)\n",
      " Call ID: call_FeH4RMy4J5xUm9u5HAuMGeXf\n",
      "  Args:\n",
      "    a: 2\n",
      "    b: 3\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "6\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of multiplying 2 and 3 is 6.\n"
     ]
    }
   ],
   "source": [
    "for event in graph.stream(None, step_to_replay.config, stream_mode=\"values\"):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673535ef-64f9-4c83-bbdc-2a23cedda054",
   "metadata": {},
   "source": [
    "## Let's clarify the concepts we have been using\n",
    "* As it usually happens with almost every document produced by the LangChain team, the LangGraph documentation is confusing and difficult to understand if we do not clarify it first. Let's clarify now the concepts we have been using in this lecture:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317152d4-1b19-49fb-898a-e5cfab42a5da",
   "metadata": {},
   "source": [
    "#### What is a step in LangGraph?\n",
    "* **step**:\n",
    "    * Normally, each node is a separate step.\n",
    "    * If we have parallel nodes in the app, the parallel nodes run in the same step.\n",
    "    * PAY ATTENTION: Frequently, the LangGraph team uses the words \"checkpoint\" and \"step\" as synonimous.\n",
    "\n",
    "#### How can we see what is in the state of an app in LangGraph?\n",
    "* **graph.get_state()** provides the most recent step.\n",
    "* **graph.get_state_history()** provides a list of all the steps.\n",
    "\n",
    "#### How can we execute an app starting from different steps in LangGraph?\n",
    "* **graph.stream(None, {thread_id})** executes graph from the most recent step.\n",
    "* **graph.stream(None, {particular_step, thread_id})** executes graph from the particular_step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed802486-4419-4e87-a82e-225a09bc7e45",
   "metadata": {},
   "source": [
    "## Forking\n",
    "* **In our debugging process, sometimes we will want to run the app from the same step but with a different input** in order to see how the app behaves with the new input. This is called forking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a32866-e54e-42d3-b53e-b5ed7f8d5bd2",
   "metadata": {},
   "source": [
    "## First, let's select the step we want to fork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e97ae18-a244-413a-9484-a8f53de6a2f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Multiply 2 and 3', additional_kwargs={}, response_metadata={}, id='bcd6c2b4-c3df-498f-9149-a9cdda9f645c')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_to_fork = all_states[-2]\n",
    "step_to_fork.values[\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3a06eae-c8ea-4a24-8f22-903bc4a18002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f008d0f-9378-6ad8-8000-19bf2a734b44'}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_to_fork.config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc96f62-e350-490c-8065-e7b3ad87b111",
   "metadata": {},
   "source": [
    "## Now, let's enter a new input for the forked step\n",
    "#### To do it, we will run update_state with the checkpoint_id associated with the forked step.\n",
    "* Remember how our reducer on messages works:\n",
    "    * It will append, unless we supply a message ID.\n",
    "    * We supply the message ID to overwrite the message, rather than appending to state.\n",
    "* **To overwrite the the message we have to supply the message ID**, which we have in step_to_fork.values[\"messages\"][0].id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e393e5ac-5a8e-4a79-b088-b8ece8be14c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f008d18-e277-6978-8001-9df11e53b54f'}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PAY ATTENTION: see how we enter the different input for the forked step\n",
    "# Now the new input for the same step will be \"Multiply 5 and 100\"\n",
    "# Instead of the previous input \"Multiply 2 and 3\"\n",
    "fork_config = graph.update_state(\n",
    "    step_to_fork.config,\n",
    "    {\"messages\": [HumanMessage(content='Multiply 5 and 100', \n",
    "                               id=step_to_fork.values[\"messages\"][0].id)]},\n",
    ")\n",
    "\n",
    "fork_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ab409d-8672-45d0-803c-4150434b6fbf",
   "metadata": {},
   "source": [
    "* **This creates a new forked step with this different input**, but the metadata of the step - e.g., where to go next - is preserved.\n",
    "* We can see that now the current state of the agent has been updated with our fork:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8922dd7d-53af-4d9a-b7a1-a370043cecd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Multiply 5 and 100', additional_kwargs={}, response_metadata={}, id='bcd6c2b4-c3df-498f-9149-a9cdda9f645c')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_states = [state for state in graph.get_state_history(thread) ]\n",
    "all_states[0].values[\"messages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7bae7343-b1a9-4e6c-a811-b6fd1cb24cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='Multiply 5 and 100', additional_kwargs={}, response_metadata={}, id='bcd6c2b4-c3df-498f-9149-a9cdda9f645c')]}, next=('assistant',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f008d18-e277-6978-8001-9df11e53b54f'}}, metadata={'source': 'update', 'writes': {'__start__': {'messages': [HumanMessage(content='Multiply 5 and 100', additional_kwargs={}, response_metadata={}, id='bcd6c2b4-c3df-498f-9149-a9cdda9f645c')]}}, 'thread_id': '1', 'step': 1, 'parents': {}, 'checkpoint_ns': '', 'checkpoint_id': '1f008d0f-9378-6ad8-8000-19bf2a734b44'}, created_at='2025-03-24T17:00:57.462406+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f008d0f-9378-6ad8-8000-19bf2a734b44'}}, tasks=(PregelTask(id='73cf7d9a-875b-7272-0053-d9ded0795900', name='assistant', path=('__pregel_pull', 'assistant'), error=None, interrupts=(), state=None, result=None),))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_state({'configurable': {'thread_id': '1'}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e31cca8-fa6f-4d93-a8b6-af8d08164ca1",
   "metadata": {},
   "source": [
    "## Finally, let's run the forked step with the new input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1dd180-15fa-4595-b0f0-3e1900e79313",
   "metadata": {},
   "source": [
    "* When we now run the app with stream, the app knows that the forked step has never been executed. So, the app runs this new step instead of replaying it.\n",
    "* Here, we will use **graph.stream()** to run the app from the forked step. As you see, the forked step with the new input is identified by fork_config:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c89df244-7cb8-4400-9669-815ece00a79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Multiply 5 and 100\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_IHbooFO8Orvf5zXhPUTuOr3d)\n",
      " Call ID: call_IHbooFO8Orvf5zXhPUTuOr3d\n",
      "  Args:\n",
      "    a: 5\n",
      "    b: 100\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "500\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of multiplying 5 and 100 is 500.\n"
     ]
    }
   ],
   "source": [
    "for event in graph.stream(None, fork_config, stream_mode=\"values\"):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d65773-5e12-4241-80f4-bf8d9bdd65d5",
   "metadata": {},
   "source": [
    "* **Regarding stream_mode=\"values\"**, remember that as we saw in a previous lecture, LangGraph supports different streaming modes for graph state:\n",
    "    * stream_mode=\"updates\": This streams only the updates to the state after each node is called.\n",
    "    * stream_mode=\"values\": This streams the full state after each node is called."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6c23f2-76b9-4c85-be0d-de5ab40462ad",
   "metadata": {},
   "source": [
    "![Simple graph](graph004.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5c2659-8f0c-4a4b-9e9a-ffff63090f72",
   "metadata": {},
   "source": [
    "## Finally, print the current state of the app\n",
    "* You will see that now the current state is the result of running the forked step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b48bac0-d146-47fb-8874-7d4b7faeb898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='Multiply 5 and 100', additional_kwargs={}, response_metadata={}, id='bcd6c2b4-c3df-498f-9149-a9cdda9f645c'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_IHbooFO8Orvf5zXhPUTuOr3d', 'function': {'arguments': '{\"a\":5,\"b\":100}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 131, 'total_tokens': 149, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_90d33c15d4', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-4660dc2a-4edc-4d28-b585-0e8e6aa44c42-0', tool_calls=[{'name': 'multiply', 'args': {'a': 5, 'b': 100}, 'id': 'call_IHbooFO8Orvf5zXhPUTuOr3d', 'type': 'tool_call'}], usage_metadata={'input_tokens': 131, 'output_tokens': 18, 'total_tokens': 149, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='500', name='multiply', id='aa2de765-55f5-4a1a-bb6c-b672afb0c5ab', tool_call_id='call_IHbooFO8Orvf5zXhPUTuOr3d'), AIMessage(content='The result of multiplying 5 and 100 is 500.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 156, 'total_tokens': 171, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_90d33c15d4', 'finish_reason': 'stop', 'logprobs': None}, id='run-08563d9a-fecc-4823-81b5-74de517ff1f9-0', usage_metadata={'input_tokens': 156, 'output_tokens': 15, 'total_tokens': 171, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f008d19-b438-6f70-8004-641721d31a4c'}}, metadata={'source': 'loop', 'writes': {'assistant': {'messages': [AIMessage(content='The result of multiplying 5 and 100 is 500.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 156, 'total_tokens': 171, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_90d33c15d4', 'finish_reason': 'stop', 'logprobs': None}, id='run-08563d9a-fecc-4823-81b5-74de517ff1f9-0', usage_metadata={'input_tokens': 156, 'output_tokens': 15, 'total_tokens': 171, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}, 'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f008d18-e277-6978-8001-9df11e53b54f', 'step': 4, 'parents': {}}, created_at='2025-03-24T17:01:19.456849+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f008d19-acc5-6752-8003-724276b2b269'}}, tasks=())"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_state({'configurable': {'thread_id': '1'}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4dbd11-d310-4a1d-b0dc-53f47ac6f805",
   "metadata": {},
   "source": [
    "## Here is a more readable format of the previous response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5361e804-7734-4723-b0b9-6851cd1dbebf",
   "metadata": {},
   "source": [
    "#### State  \n",
    "\n",
    "**Messages**:  \n",
    "1. **User Message**  \n",
    "   - **Content**: \"Multiply 5 and 100\"  \n",
    "   - **ID**: `6962373e-91bd-41cb-8cdf-f8a646b024ef`  \n",
    "\n",
    "2. **AI Message** (Initial Response)  \n",
    "   - **Content**: *(Empty)*  \n",
    "   - **Tool Call**:  \n",
    "     - **ID**: `call_KfsUs9Q0R1SNREjUDY4CIdA0`  \n",
    "     - **Function**:  \n",
    "       - **Name**: `multiply`  \n",
    "       - **Arguments**: `{\"a\": 5, \"b\": 100}`  \n",
    "     - **Type**: `function`  \n",
    "   - **Metadata**:  \n",
    "     - **Tokens Used**:  \n",
    "       - Completion: 17  \n",
    "       - Prompt: 131  \n",
    "       - Total: 148  \n",
    "     - **Model**: `gpt-4o-2024-08-06`  \n",
    "     - **Finish Reason**: `tool_calls`  \n",
    "   - **ID**: `run-fd5914b6-2f59-492d-b836-1da28f65df92-0`  \n",
    "\n",
    "3. **Tool Message** (Tool Response)  \n",
    "   - **Content**: `500`  \n",
    "   - **Tool Name**: `multiply`  \n",
    "   - **ID**: `210e31ea-1b9a-40a8-923d-c3f79efd1b1f`  \n",
    "   - **Tool Call ID**: `call_KfsUs9Q0R1SNREjUDY4CIdA0`  \n",
    "\n",
    "4. **AI Message** (Final Output)  \n",
    "   - **Content**: \"The result of multiplying 5 and 100 is 500.\"  \n",
    "   - **Metadata**:  \n",
    "     - **Tokens Used**:  \n",
    "       - Completion: 14  \n",
    "       - Prompt: 156  \n",
    "       - Total: 170  \n",
    "     - **Model**: `gpt-4o-2024-08-06`  \n",
    "     - **Finish Reason**: `stop`  \n",
    "   - **ID**: `run-92ee4d35-0e08-421f-a123-5358626c4957-0`  \n",
    "\n",
    "#### Next Steps:  \n",
    "- **Next**: *(Empty)*  \n",
    "\n",
    "#### Configuration:  \n",
    "- **Thread ID**: `1`  \n",
    "- **Checkpoint ID**: `1efbb9a4-14a2-68d2-8004-87587ff92dfc`  \n",
    "\n",
    "#### Metadata:  \n",
    "- **Source**: `loop`  \n",
    "- **Writes**:  \n",
    "  - Assistant Message: \"The result of multiplying 5 and 100 is 500.\"  \n",
    "- **Step**: `4`  \n",
    "\n",
    "#### Creation Details:  \n",
    "- **Timestamp**: `2024-12-16T10:41:06.651107+00:00`  \n",
    "\n",
    "#### Parent Configuration:  \n",
    "- **Checkpoint ID**: `1efbb9a4-082d-6250-8003-f0a795f0667b`  \n",
    "\n",
    "#### Usage Metadata:  \n",
    "- **Input Tokens**: 156  \n",
    "- **Output Tokens**: 14  \n",
    "- **Total Tokens**: 170  \n",
    "\n",
    "**Token Details**:  \n",
    "- **Input**:  \n",
    "  - Audio: 0  \n",
    "  - Cache Read: 0  \n",
    "- **Output**:  \n",
    "  - Audio: 0  \n",
    "  - Reasoning: 0  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc24f4f-d23c-4202-992d-91b0623136ae",
   "metadata": {},
   "source": [
    "## How to execute the code from Visual Studio Code\n",
    "* In Visual Studio Code, see the file 019-debugging.py\n",
    "* In terminal, make sure you are in the directory of the file and run:\n",
    "    * python 019-debugging.py\n",
    "    * Remember to add print statements in the code when necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1af248e-6069-44b3-a2cd-a20aa3259874",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new2_3114",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
